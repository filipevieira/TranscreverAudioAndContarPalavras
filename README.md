# Transcri√ß√£o de √Åudio com WhisperX

Transcreve √°udio em portugu√™s utilizando **WhisperX** (Whisper + alinhamento de palavras + diariza√ß√£o). Identifica falantes, alinha palavras e conta ocorr√™ncias de palavras-chave por falante.

## üìã Recursos

- ‚úÖ **Transcri√ß√£o de √°udio** em portugu√™s com Whisper (modelos: tiny, base, small, medium, large-v3)
- ‚úÖ **Alinhamento de palavras** em n√≠vel de palavra (sabe exatamente quando cada palavra foi dita)
- ‚úÖ **Diariza√ß√£o** (identifica√ß√£o autom√°tica de falantes)
- ‚úÖ **Contagem de palavras-chave** por falante
- ‚úÖ **Fallback para CPU** (se GPU falhar)
- ‚úÖ **Timer de progresso** (mostra quanto tempo cada etapa leva)
- ‚úÖ **Sa√≠das estruturadas** (transcri√ß√£o + estat√≠sticas)

## üöÄ Instala√ß√£o R√°pida

### 1. Clonar reposit√≥rio
```bash
git clone https://github.com/seu-usuario/transcricao-audio.git
cd transcricao-audio
```

### 2. Criar ambiente virtual (Python 3.11)
```powershell
# Windows (PowerShell)
py -3.11 -m venv .venv
.\.venv\Scripts\Activate.ps1

# macOS/Linux
python3.11 -m venv .venv
source .venv/bin/activate
```

### 3. Instalar depend√™ncias
```bash
python -m pip install --upgrade pip setuptools wheel
```

**Op√ß√£o A: CPU (simples, mais lento)**
```bash
pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cpu
pip install -r requirements.txt
```

**Op√ß√£o B: GPU CUDA 12.1** (requer NVIDIA + drivers atualizados)
```bash
pip install torch==2.1.2+cu121 torchvision==0.16.2+cu121 torchaudio==2.1.2+cu121 --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt
```

**Op√ß√£o C: GPU CUDA 11.8**
```bash
pip install torch==2.1.2+cu118 torchvision==0.16.2+cu118 torchaudio==2.1.2+cu118 --index-url https://download.pytorch.org/whl/cu118
pip install -r requirements.txt
```

## üìñ Uso

### 1. Configurar token Hugging Face (opcional)

Copie `.env.example` para `.env` e configure seu token:

```bash
cp .env.example .env
# Edite .env e cole seu token
```

Ou use vari√°vel de ambiente:
```powershell
$env:HUGGINGFACE_TOKEN = "hf_seu_token_aqui"
```

### 2. Customizar palavras-chave

Edite `palavras.json` para adicionar/remover palavras a contar:

```json
{
  "palavras": [
    "mano",
    "aburso",
    "sua_palavra",
    "outra_palavra"
  ]
}
```

Deixe array vazio para desabilitar contagem:
```json
{
  "palavras": []
}
```

### 3. Rodar

```bash
# B√°sico
python transcricao_audio.py audio.mp3

# Com modelo espec√≠fico
python transcricao_audio.py audio.mp3 --model small

# Com modelo mais preciso (lento)
python transcricao_audio.py audio.mp3 --model large-v3
```

## üìä Sa√≠da

Dois arquivos s√£o gerados (baseado no nome de entrada):

### 1. `audio.transcricao.txt`
```
Speaker 1: Ol√°, tudo bem?
Speaker 1: Como voc√™ est√°?
Speaker 2: Tudo √≥timo!
```

### 2. `audio.estatisticas.txt`
```
CONTAGEM DE PALAVRAS POR FALANTE
Speaker 1: 245 palavras
Speaker 2: 189 palavras

CONTAGEM DE PALAVRAS ESPEC√çFICAS POR FALANTE

Speaker 1:
  'mano': 3 vez(es)
  'aburso': 1 vez(es)

Speaker 2:
  'mano': 2 vez(es)
  'aburso': 0 vez(es)
```

## ‚öôÔ∏è Configura√ß√£o

### `.env` - Token Hugging Face

Copie `.env.example` para `.env`:
```bash
cp .env.example .env
```

Edite e configure seu token (pegue em https://huggingface.co/settings/tokens):
```
HUGGINGFACE_TOKEN=hf_seu_token_aqui
```

O token √© carregado automaticamente. Para seguran√ßa, **nunca** commit `.env` no GitHub (j√° est√° em `.gitignore`).

### `palavras.json` - Palavras-chave a contar

Edite para adicionar/remover palavras:
```json
{
  "palavras": [
    "mano",
    "aburso",
    "sua_palavra"
  ]
}
```

Sa√≠da mostrar√° contagem por falante para cada palavra.

### C√≥digo - Outros par√¢metros

Edite `transcricao_audio.py` para customizar:

```python
# Tamanho de lote para transcri√ß√£o
BATCH_SIZE = 32  # aumente para ~64 se tiver muita VRAM

# Modelo padr√£o
DEFAULT_MODEL = "small"  # tiny, base, small, medium, large-v3
```

## üéØ Performance

### Tempos estimados (√°udio de 1 hora, GPU Tesla T4):

| Modelo | Carga | Transcri√ß√£o | Alinhamento | Diariza√ß√£o | **Total** |
|--------|-------|-------------|-------------|-----------|----------|
| tiny   | 1m    | 2m          | 1m          | 2m        | **6m**   |
| base   | 1m    | 4m          | 1m          | 2m        | **8m**   |
| small  | 1m    | 8m          | 2m          | 2m        | **13m**  |
| medium | 2m    | 15m         | 3m          | 2m        | **22m**  |
| large  | 3m    | 25m         | 4m          | 2m        | **34m**  |

**CPU √© ~10-15x mais lento** que GPU.

### üí° Dicas de otimiza√ß√£o:
- Use modelo `small` ou `tiny` para audios longos
- Aumente `BATCH_SIZE` para 64 se tiver 8GB+ VRAM GPU
- Reduza `BATCH_SIZE` para 16 se tiver pouca mem√≥ria
- Diariza√ß√£o √© lenta; desative se n√£o precisar (n√£o configure token)

## üîß Requisitos

- **Python 3.11+**
- **PyTorch 2.1+** (CPU ou GPU)
- **FFmpeg** (para carregar √°udio)
- **Hugging Face Token** (opcional, para diariza√ß√£o)

### Instalar FFmpeg
```bash
# Windows (se n√£o tiver)
winget install -e --id Gyan.FFmpeg

# macOS
brew install ffmpeg

# Linux (Ubuntu/Debian)
sudo apt-get install ffmpeg
```

### Instalar depend√™ncias Python
```bash
pip install -r requirements.txt
# Instale tamb√©m pytorch (CPU ou GPU)
# Ver se√ß√£o "Instala√ß√£o R√°pida" acima
```

## üêõ Troubleshooting

### `ModuleNotFoundError: No module named 'whisperx'`
‚Üí Ative o venv: `.\.venv\Scripts\Activate.ps1`

### `OSError: [WinError 127] N√£o foi poss√≠vel encontrar o procedimento`
‚Üí Pytorch incompat√≠vel com GPU. O script tenta CPU automaticamente. Se quiser for√ßar CPU:
```python
device = "cpu"  # Edite a linha 37
```

### Diariza√ß√£o desativada / token inv√°lido
‚Üí Configure token Hugging Face:
```powershell
$env:HUGGINGFACE_TOKEN = "hf_seu_token"
```
Pegue seu token em https://huggingface.co/settings/tokens

### √Åudio muito longo (demora muitas horas)
‚Üí Use modelo mais r√°pido:
```bash
python transcricao_audio.py audio.mp3 --model tiny
```

## üìù Exemplo Completo

```powershell
# 1. Ativar ambiente
.\.venv\Scripts\Activate.ps1

# 2. Configurar arquivo .env (copiar template)
Copy-Item .env.example .env
# Editar .env e colar token Hugging Face

# 3. Customizar palavras (editar palavras.json se quiser)
# (opcional - j√° vem com "mano" e "aburso")

# 4. Rodar
python transcricao_audio.py meu_video.mp3 --model small

# Sa√≠da:
# ============================================================
# Dispositivo: cuda (compute_type=float16)
# Modelo: small
# Batch size: 32
# ============================================================
#
# ‚úì 2 palavra(s)-chave carregada(s) de palavras.json
# [1/5] Carregando √°udio...
# ‚úì √Åudio carregado em 0:00:05
# [2/5] Carregando modelo Whisper (small)...
# ‚úì Modelo carregado em 0:01:30
# [3/5] Transcrevendo √°udio...
# ‚úì Transcri√ß√£o conclu√≠da em 0:15:45
# [4/5] Alinhando palavras...
# ‚úì Alinhamento conclu√≠do em 0:02:10
# [5/5] Identificando falantes (diariza√ß√£o)...
# ‚úì Diariza√ß√£o conclu√≠da em 0:03:20
#
# ============================================================
# ‚úì Processamento conclu√≠do em 0:22:50
# TRANSCRI√á√ÉO: meu_video.transcricao.txt
# ESTAT√çSTICAS: meu_video.estatisticas.txt
# ============================================================
```

## üìú Licen√ßa

MIT License - Veja `LICENSE` para detalhes.

## ü§ù Contribuindo

Melhorias e sugest√µes s√£o bem-vindas! Abra uma issue ou pull request.

---

**Nota:** O primeiro uso baixa modelos (~3-5 GB para `small`, ~10 GB para `large`). Isso √© feito uma √∫nica vez.
